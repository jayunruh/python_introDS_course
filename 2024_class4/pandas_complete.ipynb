{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sort, glob, rank, iloc, loc, insert values when condition, isin\n",
    "#### create a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataframes from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create arrays \n",
    "\n",
    "gc : list\n",
    "    A list of colors\n",
    "g : array\n",
    "    An array of colors picked form gc for color of points\n",
    "x : array\n",
    "    An array with values randomly picked from a normal distribution\n",
    "y: array\n",
    "    x plus randon noise\n",
    "z : random ints from 5 to 100 for size of points\n",
    "'''\n",
    "\n",
    "gc = ['red', 'blue', 'pink', 'yellow', 'brown', 'magenta', 'green', 'orange']\n",
    "g = np.random.choice(gc, 500)  # pick an element from gc 500 times\n",
    "x = np.random.randn(500) # pick values from a random distribution\n",
    "y = x + .5*np.random.randn(500) # x plus noise\n",
    "z = np.random.randint(5, 100, 500) # random ints for size of points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A pandas DataFrame can easily be created with a dictionary using a string name\n",
    "as the key and an array or list as the value\n",
    "'''\n",
    "\n",
    "mydf = pd.DataFrame({'g':g, 'x':x, 'y':y, 'z':z})\n",
    "mydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mydf.value_counts('g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame plots\n",
    "Pandas has some plotting functionality built in:\n",
    "\n",
    "To plot a histogram of a column:\n",
    "```mydf.plot.hist(x)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf['x'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the columns in mydf to make a scatter plot with size of point using 'z'\n",
    "and the color using 'g' \n",
    "'''\n",
    "\n",
    "mydf.plot.scatter('x', 'y', s='z', c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert a new column into the dataframe\n",
    "\n",
    "mydf['dxy'] = mydf['x'] - mydf['y']\n",
    "mydf['name'] = \"Chris\"  # This will create a nw column with all rows equal to 'Chris'\n",
    "mydf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas DataFrames\n",
    "\n",
    "A pandas dataframe is similar to a spreadsheet with data in columns and rows. It is common to have data in csv file or similar that can be\n",
    "imported into python. Pandas can also read many other [types of files](https://pandas.pydata.org/pandas-docs/stable/reference/io.html) and convert them into dataframes (excel, html, xml, json, sql, ...)\n",
    "\n",
    "- We have csv files from a screen, one csv file per plate [Plate002](https://www.dropbox.com/home/Work/PythonDataScience/data?preview=Plate002.csv)\n",
    "- We also have a csv file that decribes each plates contents\n",
    "- read data csv files into DataFrames\n",
    "- combined individual DataFrames into one DataFrame\n",
    "- clean the DataFrame\n",
    "- create plate/well/object columns from other columns\n",
    "- read the plate map csv\n",
    "- clean the plate map\n",
    "- combine the plate map and the data csv\n",
    "- do some calculations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download files from dropbox\n",
    "\n",
    "url = \"https://www.dropbox.com/scl/fi/moabkzm7npb72i6kl2zn3/data.zip?rlkey=h2cl8b55yo1goj8bwfh0lof8n&dl=1\"\n",
    "\n",
    "urlretrieve(url, \"data.zip\")\n",
    "\n",
    "with zipfile.ZipFile(\"data.zip\", 'r') as zip:\n",
    "    zip.extractall()\n",
    "\n",
    "os.remove(\"data.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use os.listdir to see the files in the data directory\n",
    "\n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use glob to create a list of all csv files that start with \"Plate\"\n",
    "\n",
    "files = sorted(glob.glob('data/Plate*.csv'))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "use a for loop to iterate the filename in file and pd.read_csv to import the csv data files\n",
    "\n",
    "- create an empty list to put dataframes in\n",
    "- append dataframe for each file into the list\n",
    "- use pd.concat to concatenate the list of dataframes into on large dataframe\n",
    "'''\n",
    "\n",
    "dflist = list()\n",
    "for f in files:\n",
    "    _df = pd.read_csv(f)\n",
    "    _df['csvfile'] = f\n",
    "    dflist.append(_df)\n",
    "    \n",
    "df = pd.concat(dflist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' different ways to look at the DataFrame\n",
    "\n",
    "df.head(n) : print the first n lines of the dataframe - 5 by default \n",
    "df.tail(n) : print the last n line of the dataframe - 5 by default\n",
    "df.sample(n) : print n random lines from the dataframe - 1 by default. \n",
    "df.columns : return the column names\n",
    "'''\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use df.tail to see the last rows of the dataframe\n",
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use df.sample to see random rows from the dataframe \n",
    "Use an integer N as an argument to get N rows\n",
    "Use a frac=number - a decimal less than one to get that fraction\n",
    "'''\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unwanted columns\n",
    "\n",
    "The Unnamed... are not needed, so I want to get rid of them. The DataFrame method `drop` can do that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[0], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show df and look at the left column of numbers\n",
    "## it would be nice to have that be number from 0 to N-1\n",
    "## also look at df.index\n",
    "## the index is the name of the rows\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use reset_index to set the index column to a unique integer and\n",
    "change the name of the other column to plate_index\n",
    "'''\n",
    "\n",
    "df = df.reset_index(names='plate_index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[86]['File']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use this to explore the df['File'].str options like upper, contains, split\n",
    "df['File'].str.split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## look at string function split and get the batch ( [1] place of the split)\n",
    "\n",
    "df['batch'] = df['File'].str.split(\"/\").str[1]\n",
    "df[['File', 'batch']].sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use dataframe str methods to make a plate column\n",
    "df['plate'] = df['File'].str.split(\"/\").str[2].str.split(\"_\").str[0].str.replace(\"Plate\", \"\").astype(int)\n",
    "df[['File', 'plate']].sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise : do the same thing for the well\n",
    "\n",
    "df['well'] = df['File'].str.split(\"/\").str[2].str.split(\"_\").str[1].str.replace(\"Well\", \"\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['File', 'batch', 'plate', 'well']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping functions\n",
    "I don't like stringing together all of the str.something.str....., I find using mapping functions \"better\"\n",
    "\n",
    "A series from the dataframe has a map method. In this case there are 2 batches, we could create a map for those from a dictionary:%%!\n",
    "\n",
    "```\n",
    "batch_map = {\n",
    "    \"20240321_140300_322\":\"03/21/2024\",\n",
    "    \"20240402_081806_268\":04/02/2024\"\n",
    "}\n",
    "\n",
    "df['batch_date'] = df['batch'].map(batch_map)\n",
    "```\n",
    "A function can also be used to operate on every entry in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_map = {\n",
    "    \"20240321_140300_322\":\"03/21/2024\",\n",
    "    \"20240402_081806_268\":\"04/02/2024\"\n",
    "}\n",
    "\n",
    "df['batch_date'] = df['batch'].map(batch_map)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write a mapping function to create the object column \n",
    "## './20240321_140300_322/Plate002_Well1_Object0.tif_projection.tif'\n",
    "##                                       ******^\n",
    "\n",
    "def map_object(x):\n",
    "    bn = os.path.basename(x)\n",
    "    s = bn.split(\"_\")[2]\n",
    "    #s = s.replace(\"Object\", \"\")\n",
    "    s = s[6:]\n",
    "    dot = s.index(\".\")\n",
    "    strobj = s[:dot]\n",
    "    obj = int(strobj)\n",
    "    return obj\n",
    "\n",
    "df['object'] = df['File'].map(map_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['File', 'batch', 'plate', 'well', 'object']].sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read plate map\n",
    "\n",
    "Use pd.read_csv to read in the platemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_map = pd.read_csv(\"data/20240321_Map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_map.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I like using lower case almost all the time, so the batch, plate, well\n",
    "are slightly different.\n",
    "\n",
    "Use the dataframe rename method to change the columns in the plate_map\n",
    "'''\n",
    "plate_map=plate_map.rename({\"Batch\":\"batch\", \"Plate\":\"plate\", \"Well\":\"well\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_map.columns, df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging\n",
    "\n",
    "The dataframes df and plate_map can now be joined/merged together so\n",
    "every row will have the measurements along with the slide and sample information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the dataframe merge function to merge the dataframes\n",
    "\n",
    "merged = df.merge(plate_map, on=['batch', 'plate', 'well'],\n",
    "                  how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use how='left' and run this to see which rows in df don't have matches in plate_map\n",
    "#merged[~pd.notna(merged['Sample'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The sample column has information about feeding - food and time,\n",
    "put these into separate columns'''\n",
    "\n",
    "merged['Sample'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['food'] = merged['Sample'].str.split(\" \").str[0]\n",
    "merged['time_desc'] = merged['Sample'].str.split(\" \").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[['Sample', 'food', 'time_desc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['time_desc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write a mapping dictionary to convert the time_desc column into hours\n",
    "### Caution: don't name variables time. There is a common built in library called time\n",
    "\n",
    "feed_map = {\n",
    "    '2h': 2,\n",
    "    'unfed':0,\n",
    "    '10min': 1./60.,\n",
    "    '4h': 4, \n",
    "    '5d': 5*24,\n",
    "    '6h': 6*24,\n",
    "    '2d': 2*24,\n",
    "    '3d': 3*24,\n",
    "    '1d': 24,\n",
    "    '7d': 7*24,\n",
    "    '6d': 6*24,\n",
    "    '4d': 4*24\n",
    "}\n",
    "\n",
    "merged['time'] = merged['time_desc'].map(feed_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### mapping function if you are interested\n",
    "\n",
    "'''\n",
    "def feedtime(stime):\n",
    "    \n",
    "    if stime == 'unfed':\n",
    "        t = 0\n",
    "    elif stime.endswith('d'):\n",
    "        tmult = 24.\n",
    "        tnum = float(stime[:-1])\n",
    "        t = tnum*tmult\n",
    "    elif stime.endswith('h'):\n",
    "        tmult = 1.\n",
    "        tnum = float(stime[:-1])\n",
    "        t = tmult*tnum\n",
    "    elif stime.endswith('min'):\n",
    "        tmult = (1./60.)\n",
    "        tnum = float(stime[:-3])\n",
    "        t = tmult*tnum\n",
    "    else:\n",
    "        t = -1\n",
    "    \n",
    "    return t\n",
    "\n",
    "merged['time'] = merged['time_desc'].map(feedtime)\n",
    "'''\n",
    "\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.sample(10) #[['plate', 'well', 'food', 'time_desc', 'time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby and aggregation\n",
    "\n",
    "We want to use the area and density measurements to compare the different foods and feeding times. Multiple measurements (objects) of each case were taken, so we want to use the mean or other statistics to describe each case. Groupby lets us break the dataframe into parts that go together and do calculations.\n",
    "\n",
    "The groupby process needs the following:\n",
    "- columns to group together\n",
    "- what columns to do calculations on\n",
    "- the functions to calculate\n",
    "\n",
    "It might make sense to group things by ['plate', 'well']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do a groupby on plate and well, use the object column to count\n",
    "## then change the column to 'Density1' and the agg function to 'mean' or something else\n",
    "merged.groupby(['plate'])['Density1'].agg('mean').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Groupby with ['food', 'time'] then use the columns Area, Density1, and Density2 to agg with mean\n",
    "\n",
    "gmean = merged.groupby([\"food\", \"time\"])[['Area', 'Density1', 'Density2']].agg('max').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmean.sort_values(['food', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmean['rank'] = gmean.groupby(['food'])['Density1'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmean.sort_values(['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do this if there is time\n",
    "### use transform to use all values of a group for a calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['norm_max'] = merged.groupby(['food', 'time'])['Density1'].transform(lambda x : x/x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
